"""
Clean CICIDS2018 cho Binary Classification + CNN/LSTM
- Benign = 0, Attack = 1
- Kh√¥ng c·∫ßn IP
- X·ª≠ l√Ω chunk cho file l·ªõn
"""

import pandas as pd
import numpy as np
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

class BinaryCleaner:
    def __init__(self, input_dir, output_dir, chunk_size=500_000):
        """
        Args:
            input_dir: Th∆∞ m·ª•c ch·ª©a 10 file CSV g·ªëc
            output_dir: Th∆∞ m·ª•c l∆∞u file cleaned
            chunk_size: S·ªë d√≤ng ƒë·ªçc m·ªói l·∫ßn (quan tr·ªçng v·ªõi file 4GB)
        """
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.chunk_size = chunk_size
        
        # T·∫°o th∆∞ m·ª•c output
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # C·ªôt c·∫ßn lo·∫°i b·ªè (IP, timestamp, flow ID, ports)
        self.cols_to_remove = [
            'Src IP', 'Src_IP', 'Source IP', 
            'Dst IP', 'Dst_IP', 'Destination IP',
            'Flow ID', 'Flow_ID',
            'Timestamp',
            'Src Port', 'Src_Port',
            'Dst Port', 'Dst_Port'
        ]
        
    def standardize_columns(self, df):
        """Chu·∫©n h√≥a t√™n c·ªôt"""
        df.columns = df.columns.str.strip()
        rename_map = {
            'Src IP': 'Src_IP',
            'Dst IP': 'Dst_IP',
            'Src Port': 'Src_Port',
            'Dst Port': 'Dst_Port',
            'Flow ID': 'Flow_ID',
            ' Label': 'Label',
            'Label ': 'Label',
        }
        df.rename(columns=rename_map, inplace=True)
        df.columns = df.columns.str.replace(' ', '_')
        return df
    
    def clean_chunk(self, chunk):
        """Clean 1 chunk d·ªØ li·ªáu"""
        # Chu·∫©n h√≥a t√™n c·ªôt
        chunk = self.standardize_columns(chunk)
        
        # Ki·ªÉm tra c√≥ Label kh√¥ng
        if 'Label' not in chunk.columns:
            return None
        
        # X√≥a duplicate
        chunk = chunk.drop_duplicates()
        
        # X·ª≠ l√Ω missing values
        missing_counts = chunk.isnull().sum(axis=1)
        chunk = chunk[missing_counts <= len(chunk.columns) * 0.3]
        
        # Fill NaN cho numeric
        numeric_cols = chunk.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            if chunk[col].isnull().any():
                chunk[col].fillna(chunk[col].median(), inplace=True)
        
        # Thay inf b·∫±ng NaN r·ªìi fill
        chunk.replace([np.inf, -np.inf], np.nan, inplace=True)
        for col in numeric_cols:
            if chunk[col].isnull().any():
                chunk[col].fillna(chunk[col].median(), inplace=True)
        
        # Binary mapping: Benign=0, t·∫•t c·∫£ kh√°c=1
        chunk['Label'] = chunk['Label'].str.strip()
        chunk['Label_Binary'] = chunk['Label'].apply(
            lambda x: 0 if x == 'Benign' else 1
        )
        
        # Lo·∫°i b·ªè c√°c c·ªôt kh√¥ng c·∫ßn (IP, timestamp, ports...)
        cols_found = [c for c in self.cols_to_remove if c in chunk.columns]
        if cols_found:
            chunk = chunk.drop(columns=cols_found)
        
        # Lo·∫°i b·ªè c·ªôt Label g·ªëc, ch·ªâ gi·ªØ Label_Binary
        if 'Label' in chunk.columns:
            chunk = chunk.drop(columns=['Label'])
        
        # ƒê·ªïi t√™n Label_Binary ‚Üí Label cho d·ªÖ d√πng sau n√†y
        chunk.rename(columns={'Label_Binary': 'Label'}, inplace=True)
        
        return chunk
    
    def process_file(self, filepath):
        """X·ª≠ l√Ω 1 file CSV (support chunk cho file l·ªõn)"""
        print(f"\n{'='*70}")
        print(f"ƒêang x·ª≠ l√Ω: {filepath.name}")
        print(f"{'='*70}")
        
        # ƒê·∫øm d√≤ng nhanh
        print("ƒêang ƒë·∫øm s·ªë d√≤ng...")
        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
            total_rows = sum(1 for _ in f) - 1  # -1 v√¨ header
        print(f"  T·ªïng d√≤ng: {total_rows:,}")
        
        # X√°c ƒë·ªãnh file l·ªõn hay nh·ªè
        file_size_mb = filepath.stat().st_size / (1024 * 1024)
        print(f"  K√≠ch th∆∞·ªõc: {file_size_mb:.1f} MB")
        
        # X·ª≠ l√Ω theo chunk
        cleaned_chunks = []
        benign_count = 0
        attack_count = 0
        chunk_num = 0
        
        for chunk in pd.read_csv(filepath, chunksize=self.chunk_size, 
                         low_memory=False, encoding='utf-8', encoding_errors='ignore'):
            chunk_num += 1
            print(f"  Chunk {chunk_num}: {len(chunk):,} d√≤ng...", end='\r')
            
            cleaned = self.clean_chunk(chunk)
            if cleaned is not None and len(cleaned) > 0:
                # ƒê·∫øm nh√£n
                benign_count += (cleaned['Label'] == 0).sum()
                attack_count += (cleaned['Label'] == 1).sum()
                cleaned_chunks.append(cleaned)
        
        print()  # Newline sau progress
        
        if not cleaned_chunks:
            print("  ‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu sau khi clean!")
            return None
        
        # G·ªôp t·∫•t c·∫£ chunks
        print("  ƒêang g·ªôp chunks...")
        df_final = pd.concat(cleaned_chunks, ignore_index=True)
        
        # In th·ªëng k√™
        print(f"\n  ‚úÖ Ho√†n th√†nh:")
        print(f"    - D√≤ng cu·ªëi c√πng: {len(df_final):,}")
        print(f"    - Features: {len(df_final.columns) - 1}")  # -1 v√¨ Label
        print(f"    - Benign: {benign_count:,} ({benign_count/len(df_final)*100:.1f}%)")
        print(f"    - Attack: {attack_count:,} ({attack_count/len(df_final)*100:.1f}%)")
        
        # L∆∞u file cleaned
        output_path = self.output_dir / f"cleaned_{filepath.stem}.csv"
        df_final.to_csv(output_path, index=False)
        print(f"    - ƒê√£ l∆∞u: {output_path.name}")
        
        return df_final
    
    def process_all(self):
        """X·ª≠ l√Ω t·∫•t c·∫£ 10 files"""
        print("="*70)
        print("CLEAN CICIDS2018 - BINARY CLASSIFICATION")
        print("="*70)
        
        csv_files = sorted(self.input_dir.glob('*.csv'))
        if not csv_files:
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y file CSV trong {self.input_dir}")
            return
        
        print(f"\nüìÅ T√¨m th·∫•y {len(csv_files)} file")
        
        total_benign = 0
        total_attack = 0
        
        for i, filepath in enumerate(csv_files, 1):
            print(f"\n{'#'*70}")
            print(f"File {i}/{len(csv_files)}")
            df = self.process_file(filepath)
            
            if df is not None:
                total_benign += (df['Label'] == 0).sum()
                total_attack += (df['Label'] == 1).sum()
        
        # T·ªïng k·∫øt
        print("\n" + "="*70)
        print("‚úÖ HO√ÄN T·∫§T CLEAN T·∫§T C·∫¢ FILES!")
        print("="*70)
        print(f"T·ªïng Benign: {total_benign:,}")
        print(f"T·ªïng Attack: {total_attack:,}")
        print(f"T·ª∑ l·ªá: {total_benign/(total_benign+total_attack)*100:.1f}% Benign")
        print(f"\nFile cleaned ƒë√£ l∆∞u t·∫°i: {self.output_dir}")

